{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average* per year of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "#first We need to import the data as a dataframe of course it means importing pandas\n",
    "#create a unique dataframe with country:date::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import glob\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create a column with name of the country in the beginning of the frame\n",
    "def add_pays(data_frame, pays):\n",
    "    data_frame.loc[:,'Pays'] = pd.Series(pays, index=data_frame.index)\n",
    "    cols = list(data_frame)\n",
    "    cols.insert(0, cols.pop(cols.index('Pays')))\n",
    "    data_frame = data_frame.loc[:, cols]\n",
    "    return data_frame\n",
    "\n",
    "#import the csv files of one country and put them in one frame\n",
    "def create_oneframe(pays):\n",
    "    allFiles = glob.glob(DATA_FOLDER + \"/ebola/%s_data/*.csv\"%pays)\n",
    "    list_ = []\n",
    "    frame=pd.DataFrame()\n",
    "    for file_ in allFiles:\n",
    "        df = pd.read_csv(file_,)\n",
    "        if not frame.empty:\n",
    "            frame = pd.merge(frame, df, how='outer')\n",
    "        else :\n",
    "            frame = df\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pays1='guinea'\n",
    "pays2='liberia'\n",
    "pays3='sl'   #Sierra Leone\n",
    "\n",
    "guinea=add_pays(create_oneframe(pays1),(pays1))\n",
    "liberia=add_pays(create_oneframe(pays2),(pays2))\n",
    "sl=add_pays(create_oneframe(pays3),(pays3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_country=pd.DataFrame()\n",
    "all_country=pd.merge(sl,guinea,how='outer')\n",
    "all_country=pd.merge(all_country,liberia,how='outer')\n",
    "\n",
    "##create a new column for country that dont have one. guinea:Totals, liberia:National\n",
    "## and a new date and new description\n",
    "#all_country=all_country.fillna('')\n",
    "all_country[\"Description\"] = all_country[\"Description\"].fillna('').map(str) + all_country[\"Variable\"].fillna('').map(str)+all_country[\"variable\"].fillna('').map(str)\n",
    "all_country[\"Date\"] = all_country[\"Date\"].fillna('').map(str) + all_country[\"date\"].fillna('').map(str)\n",
    "all_country['National']=all_country['National'].fillna('').map(str)+all_country['Totals'].fillna('').map(str)\n",
    "\n",
    "##Delete the old ones\n",
    "cols = list(all_country)\n",
    "cols.pop(cols.index('Variable'))\n",
    "cols.pop(cols.index('variable'))\n",
    "cols.pop(cols.index('date'))\n",
    "cols.pop(cols.index('Totals'))\n",
    "cols.insert(1, cols.pop(cols.index('Date')))\n",
    "cols.insert(2, cols.pop(cols.index('Description')))\n",
    "cols.insert(3, cols.pop(cols.index('National')))\n",
    "all_country = all_country.loc[:, cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0%'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a98058ab66a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Due to the impossibility to delete % We chose to avoid those lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m  \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m818\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m1150\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mall_country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNatio_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 3410\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 471\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0%'"
     ]
    }
   ],
   "source": [
    "#TODO: search for missing values in National: if empty sum following columns\n",
    "###Pour remplir les totaux vides\n",
    "Natio_empty=np.where((all_country.National==''))[0]\n",
    "\n",
    "\n",
    "all_country.replace({'-':0},inplace=True)\n",
    "for i in all_country.index[Natio_empty]:\n",
    "    #Due to the impossibility to delete % We chose to avoid those lines\n",
    "    if  i!=818 and i!=1150:\n",
    "        all_country.iloc[i,3]=pd.Series.sum(all_country.iloc[i,4:].astype(float))\n",
    "\n",
    "display(all_country.iloc[(all_country.index[Natio_empty])].head())\n",
    "\n",
    "###or delete those rows \n",
    "\n",
    "#print(len(Natio_empty))\n",
    "#print(len(all_country))\n",
    "#all_country.drop(all_country.index[Natio_empty],inplace=True)\n",
    "\n",
    "### The rows deleted are not important for the main Description\n",
    "\n",
    "#display(all_country.index[Natio_empty])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we have a dataframe with which we can work. \n",
    "#The goal here is to calculate the daily average of each description since it is not clear which one is necessary\n",
    "\n",
    "\n",
    "countries=['guinea','liberia','sl']\n",
    "\n",
    "#create new column with our daily average\n",
    "all_country['Daily Average']=np.nan\n",
    "cols = list(all_country)\n",
    "cols.insert(3, cols.pop(cols.index('Daily Average')))\n",
    "all_country = all_country.loc[:, cols]\n",
    "\n",
    "for country in countries:\n",
    "    #work with dataframe of the country\n",
    "    one_country=all_country[all_country.Pays.str.startswith(country)]\n",
    "    descriptions=one_country.Description.unique()\n",
    "    for desc in (descriptions[5:6]):\n",
    "        one_description=one_country.loc[one_country.Description==desc,:]\n",
    "        #does not work very weird:\n",
    "        #one_description=one_country.loc[one_country.Description.str.contains('New case/s con')]\n",
    "        if (True in one_description['National'].str.contains(',').values+\\\n",
    "            one_description['National'].str.contains('%').values):\n",
    "            print('description rejected:%s'%(desc))\n",
    "        else: \n",
    "            descr_mean=(one_description['National']).astype(float).mean()\n",
    "            if ((\"new\" not in desc) and ('New' not in desc)) and len(one_description['National'])!=0:\n",
    "                descr_mean=max(one_description['National'].astype(float))/len(one_description['National'])\n",
    "            #print(descr_mean)\n",
    "            all_country.loc[(all_country.Pays==country) \\\n",
    "                            & (all_country.Description==desc),'Daily Average']=descr_mean\n",
    "        \n",
    "        #all_country[(all_country.Pays.any()==country) and (all_country.Description==desc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now for anytype of Description it is possible to have the daily average easily:\n",
    "\n",
    "descr_dict={}\n",
    "description='new_contacts'\n",
    "for country in countries:\n",
    "    average=all_country.loc[(all_country.Pays==country)& (all_country.Description.str.contains(description)),:]['Daily Average'].unique()\n",
    "    descr_dict[country]=average\n",
    "print('For the description:\"%s\" \\n %s'%(description,descr_dict))\n",
    "\n",
    "#or just plot the full data frame for a specific country and description\n",
    "display(all_country.loc[(all_country.Pays=='liberia') & (all_country.Description.str.contains('New')),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here the new death confirmed and new cases confirmed  are calculated for each country in a slightly different way\n",
    "death_dict={}\n",
    "newcase_dict={}\n",
    "#Boolean to print the evolution of the new death confirmed and new cases confirmed \n",
    "print_evolution=False\n",
    "for country in countries:\n",
    "\n",
    "    one_country=all_country[all_country.Pays.str.startswith(country)]\n",
    "\n",
    "    #frame with only rows of new cases confirmed:\n",
    "    country_new=one_country[one_country.Description.str.contains('New',case=False)& (one_country.Description.str.contains('confirmed'))\\\n",
    "                             &(~one_country.Description.str.contains('Death',case=False))&(~one_country.Description.str.contains('workers',case=False))]\n",
    "    #average over the columns\n",
    "    #news cases confirmed daily average over the year\n",
    "    newcase_dict[country]=(country_new.National.astype(float).mean())\n",
    "    #frame with only rows of death cases confirmed:\n",
    "    country_death=one_country[one_country.Description.str.contains('deaths',case=False) & ~(one_country.Description.str.contains('HCW'))\\\n",
    "                             &(one_country.Description.str.contains('new',case=False)) &~(one_country.Description.str.contains('proba'))\\\n",
    "                             &~(one_country.Description.str.contains('workers'))&~(one_country.Description.str.contains('confirmed'))]\n",
    "    #daily death average over year :\n",
    "    death_dict[country]=(country_death.National.astype(float).mean())\n",
    "    \n",
    "    ###plot of the new cases:\n",
    "    date=country_death.Date.tolist()\n",
    "    date=[parse(x) for x in date]\n",
    "    newcase=country_new.National.astype(float).tolist()\n",
    "    date, newcase = zip(*sorted(zip(date, newcase)))\n",
    "    \n",
    "    \n",
    "    ###plot of the death everyday (in increasing date)\n",
    "    date=country_death.Date.tolist()\n",
    "    date=[parse(x) for x in date]\n",
    "    death=country_death.National.astype(float).tolist()\n",
    "    date, death = zip(*sorted(zip(date, death)))\n",
    "    if print_evolution:\n",
    "\n",
    "        plt.plot(newcase)\n",
    "        plt.title(country)\n",
    "        plt.xlabel('Days')\n",
    "        plt.ylabel('New cases')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(death)\n",
    "        plt.title(country)\n",
    "        plt.xlabel('Days')\n",
    "        plt.ylabel('New Deaths')\n",
    "        plt.show()\n",
    "\n",
    "print('New cases average:%s'%newcase_dict)\n",
    "print('death average:%s'%death_dict)\n",
    "print('Libera was the most affected country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the data for each MID file\n",
    "microbiomePath = '../../Data/microbiome/MID'\n",
    "\n",
    "for x in range(1, 10):\n",
    "    path = \"../../Data/microbiome/MID#.xls\"\n",
    "    path = path.replace('#',str(x))\n",
    "    globals()['mb%s' % x] = pd.read_excel( path, header=None, index_col=0)\n",
    "   # print(globals()['mb%s' % x].head())\n",
    "#Loading Metadata as DataFrame \n",
    "\n",
    "metaData = pd.read_excel('../../Data/microbiome/metadata.xls')\n",
    "metaData.loc[0,'SAMPLE'] = 'unknown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create a list of DataFrames to facilitate the manipulation of the DataFrames\n",
    "mbArray = [mb1,mb2,mb3,mb4,mb5,mb6,mb7,mb8,mb9]\n",
    "count = 0;\n",
    "# Adding Group and Sample for each microbiome DataFrame with the expected values from the metaData \n",
    "for x in mbArray :\n",
    "    Group = np.repeat(metaData.loc[count,'GROUP'],len(x.index))\n",
    "    Sample = np.repeat(metaData.loc[count,'SAMPLE'],len(x.index))\n",
    "    x.columns = ['Values']\n",
    "    x['Group'] = pd.Series(Group, index=x.index)\n",
    "    x['Sample'] = pd.Series(Sample, index=x.index)\n",
    "    x.index.name = 'Taxon'\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating an array with all the dataFrames\n",
    "originalTables = []\n",
    "for x in range (1,10):\n",
    "    key = 'MID#'\n",
    "    key = key.replace('#',str(x))\n",
    "    originalTables.append(key)\n",
    "    \n",
    "finalMicrobiome = pd.concat(mbArray, keys=originalTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "finalMicrobiome.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalMicrobiome[::30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename= DATA_FOLDER +'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Excel file titanic.xls\n",
    "titanic_data = pd.read_excel(DATA_FOLDER + '/titanic.xls') # size 1309 x 14\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cleaning data ##\n",
    "# Before starting, one needs to clean the data and do some data transformations\n",
    "\n",
    "# First check NaN values in the data\n",
    "titanic_data.isnull().any(); \n",
    "# This line told us what attributes get NaN values. As one can see only attribute for age, fare, cabin,embarked,boat,body and home.dest have Nan Values\n",
    "# Now that we know which attributes have Nan Values, it is good to check the number of Nan Values for each attribute.\n",
    "titanic_data.isnull().sum()\n",
    "# One can see that cabin, boat and body have significant amounts of NaN value, therefore we cannot drop the entire row when there are NaN values for these attributes\n",
    "# The number of NaN values specially for boat and cabin attributes are not the same as in the HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- 1 -- ## \n",
    "print('The type of each attribute is shown in the table below : ', end='\\n')\n",
    "print(titanic_data.dtypes) # Showing the type of each attribute\n",
    "print('The value range of each attribute is shown in the table below : ', end='\\n\\n')\n",
    "print(titanic_data.describe())\n",
    "\n",
    "titanic_data['boat'] = titanic_data.boat.replace({'C D' : np.nan, '5 7': np.nan, '13 15': np.nan , '15 16' : np.nan, '5 9': np.nan, '13 15 B':np.nan, '8 10': np.nan }) # Change the value when there are multiple life boat number and put a Nan Value because when cannot know in which boat the passenger was in.\n",
    "categorical_map = np.array(['pclass','survived','sex','embarked','boat','sibsp','parch']) # List of attributes that can be categorical (see discussion below for more informations)\n",
    "     \n",
    "for x in categorical_map : # This loop transforms the attributes that can be categorical.\n",
    "    titanic_data[x] = titanic_data[x].astype('category')\n",
    "    print(titanic_data[x].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 1 :\n",
    "- Regarding the type table, one can notice that the age's type is float64 but it could make more sense. However if it was in int64 but if the age was determine by the birth date then it makes sense\n",
    "- Besides, one can notice that the types of the ticket number, life boat number and the cabin number are object because there are some letters in the values\n",
    "\n",
    "- In the table, the value range is determine by [min,max]. One cant notice that there were babies and old person on the boat and the number of body identification is equal to 328 which is approximatively the number of body found. Also, some passengers didn't pay their ticket (free ticket)\n",
    "\n",
    "- Categoricals are pandas datatype : a variable, which can take on only a limited and usually fixed, number of possible values\n",
    "- Assumptions : boat = life boat according to us, we can put Nan Value for the passengers that have more than one value because unlike the cabine where a passenger could reserve more than 1 cabin a passenger couldn't have been in 2 different boat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- 2 -- ##\n",
    "# Plot 4 histograms using plot with kind = 'bar' and value_counts\n",
    "plt.subplot(141)\n",
    "titanic_data['pclass'].value_counts().plot(title = 'Travel class', kind='bar', grid = True) \n",
    "plt.subplot(142)\n",
    "titanic_data['sex'].value_counts().plot(title = 'Gender', kind='bar', grid = True)\n",
    "plt.subplot(143)\n",
    "titanic_data['embarked'].value_counts().plot(title = 'Embarkation port', kind='bar', grid = True)\n",
    "plt.subplot(144)\n",
    "age_noNA = titanic_data['age'].dropna() # Drop NaN values to make sure they didn't bias the result\n",
    "pd.cut(age_noNA,[0,10,20,30,40,50,60,70,80]).value_counts().plot(title = 'age', kind='bar', grid = True) #We don't need more than 80 years old since the maximun age is 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 2 :\n",
    "- Regarding the histograms, one can notice that there were more passenger travelling in Third class\n",
    "- There were more male than female, almost twice\n",
    "- Majority of the passengers embarked on port S\n",
    "- One can notice that there were a lot of young passenger between 0 and 50 years old. 20 - 30 years old passengers were the greatest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- 3 -- ##\n",
    "\n",
    "titanic_data['cabin'] = titanic_data.cabin.replace({'T': np.nan }) # Drop the T value (see discussion below for more informations)\n",
    "titanic_data['cabin_floor'] = titanic_data.cabin.copy().str[0] # Taking only the first letter which corresponds to the Floor\n",
    "titanic_data['cabin_floor'] = titanic_data.cabin_floor.astype('category') # Create category for each floor\n",
    "floor = np.zeros(len(titanic_data.cabin_floor.cat.categories))\n",
    "for i,x in enumerate(titanic_data.cabin_floor.cat.categories) : # Loop to calculate the proportion for each Cabin floor\n",
    "    floor[i] = titanic_data['cabin_floor'].value_counts()[i]*100/titanic_data['cabin_floor'].value_counts().sum() # Number of passenger of each floor divided by the number of passenger for which we know on what floor they were. \n",
    "    print('The percentage of passenger on Cabin Floor ' + x + ' is equal to %f percent' % floor[i]) \n",
    "    i = i+1\n",
    "    \n",
    "titanic_data['cabin_floor'].value_counts().plot(title = 'Cabin Floor', kind='pie') # Plot the proportion in a pie chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 3 :\n",
    "-  Assumptions : regarding the data and the HTML, passengers which have more than one cabine are on the same cabin floor\n",
    "- Besides, regarding the map of all the deck of the titanic, one can notice that one floor F there are different section such as G or E, so for instance the cabin F EXX is on the F floor.\n",
    "- The cabin T could be a typo or this cabin exist but since we don't know on which floor the cabin is, we just replace the value by NaN value.\n",
    "- Assumptions : To calculate the proportion we are taking the number of passenger on each floor divided by the total number of passenger that we know on which floor they were, and not the number total of passengers\n",
    "- One can notice that the floor B,C and D were the most occupied which makes sense since this floor corresponds to third and second class which were the greatest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- 4 -- ##\n",
    "titanic_data.survived.cat.categories = ['Dead', 'Survived']\n",
    "pclass_grouped = titanic_data.groupby(titanic_data.pclass) # Group the passenger in each travel class\n",
    "class_dict = dict(list(pclass_grouped))\n",
    "\n",
    "# Calculate proportion\n",
    "class1 = class_dict[1].survived.value_counts()[1]*100/(class_dict[1].survived.value_counts().sum())\n",
    "class2 = class_dict[2].survived.value_counts()[1]*100/(class_dict[2].survived.value_counts().sum())\n",
    "class3 = class_dict[3].survived.value_counts()[1]*100/(class_dict[3].survived.value_counts().sum())\n",
    "\n",
    "print('The proportion of the passengers that survived for class 1 is : %f percent' % class1 )\n",
    "print('The proportion of the passengers that survived for class 2 is : %f percent' % class2 )\n",
    "print('The proportion of the passengers that survived for class 3 is : %f percent' % class3 )\n",
    "\n",
    "# Pie charts\n",
    "plt.subplot(131)\n",
    "class_dict[1].survived.value_counts().plot(title = 'Class 1 Survival', kind='pie')\n",
    "plt.subplot(132)\n",
    "class_dict[2].survived.value_counts().plot(title = 'Class 2 Survival', kind='pie')\n",
    "plt.subplot(133)\n",
    "class_dict[3].survived.value_counts().plot(title = 'Class 3 Survival', kind='pie') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 4 :\n",
    "- One can notice that the proportion of passenger that survived in First class is more important that the 2 others. And the class with the lower proportion of survival is the Third class which makes sense since they were on the floors that were lower and therefore were far from the life boat and first affected by the sinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## -- 5 -- ##\n",
    "f_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "m_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "sex_class_grouped = titanic_data.groupby(['pclass','sex']) # Group the passenger by travel class and sex\n",
    "sex_class_dict = dict(list(sex_class_grouped))\n",
    "\n",
    "for i,x in enumerate(titanic_data.pclass.cat.categories): # Loop that calculate the proportion of survival for each travel class and sex\n",
    "    f_sur[i] = sex_class_dict[x,'female'].survived.value_counts()[1]*100/sex_class_dict[x,'female'].survived.value_counts().sum()\n",
    "    m_sur[i] = sex_class_dict[x,'male'].survived.value_counts()[1]*100/sex_class_dict[x,'male'].survived.value_counts().sum()\n",
    "    print('For Class' + str(x))\n",
    "    print('The percentage of passenger female that survived is : %f' % f_sur[i] +'percent')\n",
    "    print('The percentage of passenger male that survived is : %f' % m_sur[i] +'percent')\n",
    "    \n",
    "# Create a single histogram which represents the proportion of survival for each travel class and sex\n",
    "travel = [1,2,3]\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(titanic_data.pclass.cat.categories))\n",
    "opacity = 0.5\n",
    "plt.bar(x,f_sur,bar_width, color ='green', label = 'Female', alpha = opacity)\n",
    "plt.bar(x + bar_width ,m_sur ,bar_width, color ='orange', label = 'Male', alpha = opacity)\n",
    "plt.legend()\n",
    "plt.xlabel('Travel Class')\n",
    "plt.ylabel('Percentage of Survival')\n",
    "plt.title('Survival by travel class and sex')\n",
    "plt.xticks(x +bar_width, travel)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 5 :\n",
    "- One can notice that the proportion of female that survived is higher that for male and this for each travel class. Besides the highest proportion of female that survived is in First class and lowest is in the Third Class\n",
    "- One can notice that the proportion of male that survived in general is much lower that for female which makes sense because during a sinking the children and women are the first saved (Children and Ladies First !). And again the proportion of survival is higher in First class than the 2 other travel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age_noNA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a3e7a692316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## -- 6 -- ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPop_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_noNA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m523\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Create 2 equally populated age categories by sorting the age's values and taking the first 523 one since the number of age's value is 1046\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mPop_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_noNA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m524\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf_old_sur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'age_noNA' is not defined"
     ]
    }
   ],
   "source": [
    "## -- 6 -- ##\n",
    "Pop_1 = age_noNA.sort_values()[:523] # Create 2 equally populated age categories by sorting the age's values and taking the first 523 one since the number of age's value is 1046\n",
    "Pop_2 = age_noNA.sort_values()[524:]\n",
    "\n",
    "f_old_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "m_old_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "f_young_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "m_young_sur = np.zeros(len(titanic_data.pclass.cat.categories))\n",
    "\n",
    "# Add new column in the dataframe with value 'Young' for the first group and 'Old' for the second group\n",
    "\n",
    "population1 = pd.Series(['Young']*len(Pop_1.index), Pop_1.index) \n",
    "titanic_data['eq_pop'] = population1\n",
    "titanic_data['eq_pop'] = titanic_data['eq_pop'].fillna(value ='Old')\n",
    "titanic_data['eq_pop'] = titanic_data['eq_pop'].astype('category')\n",
    "titanic_data.eq_pop.cat.categories = ['Old', 'Young']\n",
    "\n",
    "sex_class_survived_grouped = titanic_data.groupby(['pclass','sex','survived']) # Group the passengers by travel class, sex and survival\n",
    "sex_class_survived_dict = dict(list(sex_class_survived_grouped))\n",
    "\n",
    "for i,x in enumerate(titanic_data.pclass.cat.categories):\n",
    "    f_young_sur[i] = sex_class_survived_dict[x,'female','Survived'].eq_pop.value_counts()[1]*100/sex_class_dict[x,'female'].survived.value_counts().sum()\n",
    "    f_old_sur[i] = sex_class_survived_dict[x,'female','Survived'].eq_pop.value_counts()[0]*100/sex_class_dict[x,'female'].survived.value_counts().sum()\n",
    "    m_young_sur[i] = sex_class_survived_dict[x,'male','Survived'].eq_pop.value_counts()[1]*100/sex_class_dict[x,'male'].survived.value_counts().sum()\n",
    "    m_old_sur[i] = sex_class_survived_dict[x,'male','Survived'].eq_pop.value_counts()[0]*100/sex_class_dict[x,'male'].survived.value_counts().sum()\n",
    "    print('For Class' + str(x))\n",
    "    print('The percentage of passenger young female that survived is : %f' % f_young_sur[i] +'percent')\n",
    "    print('The percentage of passenger old female that survived is : %f' % f_old_sur[i] +'percent')\n",
    "    print('The percentage of passenger young male that survived is : %f' % m_young_sur[i] +'percent')\n",
    "    print('The percentage of passenger old male that survived is : %f' % m_old_sur[i]+'percent')\n",
    "\n",
    "# Create one histogram that represents the proportion of survival depending on the travel class, sex, and the age's group\n",
    "travel = [1,2,3]\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(titanic_data.pclass.cat.categories))\n",
    "opacity = 0.5\n",
    "plt.bar(x,f_young_sur,bar_width, color ='green', label = 'Young Female', alpha = opacity)\n",
    "plt.bar(x,f_old_sur,bar_width, color ='blue', label = 'Old Female', alpha = opacity, bottom = f_young_sur)\n",
    "plt.bar(x + bar_width ,m_young_sur ,bar_width, color ='orange', label = 'Young Male', alpha = opacity)\n",
    "plt.bar(x + bar_width ,m_old_sur ,bar_width, color ='red', label = 'Old Male', alpha = opacity, bottom = m_young_sur)\n",
    "plt.legend()\n",
    "plt.xlabel('Travel Class')\n",
    "plt.ylabel('Percentage of Survival')\n",
    "plt.title('Survival by travel class, sex and age')\n",
    "plt.xticks(x +bar_width, travel)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 6 :\n",
    "- One can notice that for both male and female the proportion of passenger who belong to the second that survived is higher than the other group for the First class unlike the 2 other travel class where the first group have a higher proportion of survival. \n",
    "- Besides, the difference between the 2 groups in much more important for the first class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General conclusion :\n",
    "- Regarding the proportion of passengers that survived. One can notice that there were a huge inegality of survival between the different travel class. Indeed, although the passenger of the second and third class were on lower decks so far from the life boats and the first affected by the water in the boat, we remembered that some of the rich passengers paid some amounts of money to get in the life boats.\n",
    "- Besides, it makes sense that the proportion of women that survived is higher.\n",
    "\n",
    "In conclusion, during the sinking of the Titanic, a class war really took place and the first class (rich people) won (at least for the women). However, we will remember the courtesy of the men who saved the children and women first (as we can see that the proportion of women that survived is much higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
